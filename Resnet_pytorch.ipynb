{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOsoNey64PR92wi+ZMBpkPq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuanAII/ResNet_CIFAR-10/blob/main/Resnet_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oKb94FP_SDAk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBloc(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, stride):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
        "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != out_planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return F.relu(out)\n"
      ],
      "metadata": {
        "id": "3RTSmQEFSt22"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet-20 cho CIFAR-10\n",
        "class ResNet20(nn.Module):\n",
        "    def __init__(self, block= ResidualBloc, num_blocks=[3,3,3], num_classes=10):\n",
        "        super(ResNet20, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for s in strides:\n",
        "            layers.append(block(self.in_planes, out_planes, s))\n",
        "            self.in_planes = out_planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)  # 32x32\n",
        "        out = self.layer2(out)  # 16x16\n",
        "        out = self.layer3(out)  # 8x8\n",
        "        out = self.avgpool(out)  # 1x1\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "dzUH0oNzSt5K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# data processinh\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,\n",
        "                                        transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,\n",
        "                                       transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x634dLfRWO_m",
        "outputId": "0c346d9c-15c8-481d-abf3-2b93ff7b9047"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:14<00:00, 11.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "net = ResNet20().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)\n",
        "\n",
        "# Huấn luyện\n",
        "for epoch in range(1, 30):\n",
        "    net.train()\n",
        "    running_loss = 0\n",
        "    for inputs, targets in trainloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch {epoch}, Loss: {running_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnsZyNQkSt71",
        "outputId": "8ee404eb-7dfb-4397-cbcd-95115f139d4c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 654.8669\n",
            "Epoch 2, Loss: 467.6530\n",
            "Epoch 3, Loss: 351.6413\n",
            "Epoch 4, Loss: 304.7737\n",
            "Epoch 5, Loss: 278.3147\n",
            "Epoch 6, Loss: 260.8681\n",
            "Epoch 7, Loss: 249.1437\n",
            "Epoch 8, Loss: 242.3949\n",
            "Epoch 9, Loss: 234.2127\n",
            "Epoch 10, Loss: 228.1078\n",
            "Epoch 11, Loss: 220.3091\n",
            "Epoch 12, Loss: 215.6382\n",
            "Epoch 13, Loss: 214.6277\n",
            "Epoch 14, Loss: 210.7878\n",
            "Epoch 15, Loss: 208.7773\n",
            "Epoch 16, Loss: 208.1936\n",
            "Epoch 17, Loss: 202.3052\n",
            "Epoch 18, Loss: 203.0416\n",
            "Epoch 19, Loss: 199.8583\n",
            "Epoch 20, Loss: 197.2634\n",
            "Epoch 21, Loss: 197.5532\n",
            "Epoch 22, Loss: 197.2686\n",
            "Epoch 23, Loss: 192.2971\n",
            "Epoch 24, Loss: 191.6381\n",
            "Epoch 25, Loss: 190.6552\n",
            "Epoch 26, Loss: 192.8948\n",
            "Epoch 27, Loss: 190.0158\n",
            "Epoch 28, Loss: 188.1512\n",
            "Epoch 29, Loss: 188.2923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(net, loader):\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "acc = evaluate(net, testloader)\n",
        "print(f\"Accuracy on test set: {acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UD5fTNgSuAW",
        "outputId": "cda14e8f-3832-46a3-c45e-7ea9d49bb768"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 73.20%\n"
          ]
        }
      ]
    }
  ]
}